arXiv:1901.01085v1  [cs.SD]  4 Jan 2019
Introduction to Voice Presentation Attack
Detection and Recent Advances
Md Sahidullah, H´ector Delgado, Massimiliano Todisco, Tomi Kinnunen, Nicholas
Evans, Junichi Yamagishi and Kong-Aik Lee
Abstract Over the past few years signiﬁcant progress has been made in the ﬁeld
of presentation attack detection (PAD) for automatic speaker recognition (ASV).
This includes the development of new speech corpora, standard evaluation proto-
cols and advancements in front-end feature extraction and back-end classiﬁers. The
use of standard databases and evaluation protocols has enabled for the ﬁrst time
the meaningful benchmarking of different PAD solutions. This chapter summarises
the progress, with a focus on studies completed in the last three years. The article
presents a summary of ﬁndings and lessons learned from two ASVspoof challenges,
the ﬁrst community-led benchmarking efforts. These show that ASV PAD remains
an unsolved problem and that further attention is required to develop generalised
Md Sahidullah
School of Computing, University of Eastern Finland (Finland), e-mail: sahid@cs.uef.fi
[Currently with Inria, France.]
H´ector Delgado
Department
of
Digital
Security,
EURECOM
(France)
e-mail:
hector.delgado@eurecom.fr
Massimiliano Todisco
Department
of
Digital
Security,
EURECOM
(France)
e-mail:
massimiliano.todisco@eurecom.fr
Tomi Kinnunen
School of Computing, University of Eastern Finland (Finland), e-mail: tkinnu@cs.uef.fi
Nicholas Evans
Department of Digital Security, EURECOM (France) e-mail: evans@eurecom.fr
Junichi Yamagishi
National Institute of Informatics (Japan) and University of Edinburgh (United Kingdom) e-mail:
jyamagis@nii.ac.jp
Kong-Aik Lee
Data
Science
Research
Laboratories,
NEC
Corporation
(Japan)
e-mail:
k-lee@ax.jp.nec.com
2
Authors Suppressed Due to Excessive Length
PAD solutions which have potential to detect diverse and previously unseen spoof-
ing attacks.
1 Introduction
Automatic speaker veriﬁcation (ASV) technology aims to recognise individuals us-
ing samples of the human voice signal [1, 2]. Most ASV systems operate on esti-
mates of the spectral characteristics of voice in order to recognise individual speak-
ers. ASV technology has matured in recent years and now ﬁnds application in a
growing variety of real-world authentication scenarios involving both logical and
physical access. In scenarios, ASV technology can be used for remote person au-
thentication via the Internet or traditional telephony. In many cases, ASV serves as a
convenient and efﬁcient alternative to more conventional password-based solutions,
one prevalent example being person authentication for Internet and mobile banking.
scenarios include the use of ASV to protect personal or secure/sensitive facilities,
such as domestic and ofﬁce environments. With the growing, widespread adoption
of smartphones and voice-enabled smart devices, such as intelligent personal assis-
tants all equipped with at least one microphone, ASV technology stands to become
even more ubiquitous in the future.
Despite its appeal, the now-well-recognisedvulnerability to manipulation through
presentation attacks (PAs), also known as spooﬁng, has dented conﬁdence in ASV
technology. As identiﬁed in ISO/IEC 30107-1 standard [3], the possible locations of
presentation attack points in a typical ASV system are illustrated in Fig. 1. Two of
the most vulnerable places in an ASV system are marked by 1 and 2, correspond-
ing to physical access and logical access. This work is related to these two types of
attacks.
Unfortunately, ASV is arguably more prone to PAs than other biometric systems
based on traits or characteristics that are less-easily acquired; samples of a given per-
son’s voice can be collected readily by fraudsters through face-to-face or telephone
conversations and then replayed in order to manipulate an ASV system. Replay
attacks are furthermore only one example of ASV PAs. More advanced voice con-
version or speech synthesis algorithms can be used to generate particularly effective
PAs using only modest amounts of voice data collected from a target person.
There are a number of ways to prevent PA problems. The ﬁrst one is based on
a text-prompted system which uses an utterance veriﬁcation process [4]. The user
needs to utter a speciﬁc text, prompted for authentication by the system which re-
quires a text-veriﬁcation system. Secondly, as human can never reproduce an iden-
tical speech signal, some countermeasures use template matching or audio ﬁnger-
printing to verify whether the speech utterance was presented to the system ear-
lier [5]. Thirdly, some work looks into statistical acoustic characterisation of au-
thentic speech and speech created with presentation attack methods or spooﬁng
techniques [6]. Our focus is on the last category, which is more convenient in a
practical scenario for both text-dependent and text-independent ASV. In this case,
Introduction to Voice Presentation Attack Detection and Recent Advances
Microphone
Feature
Extraction
Classifier
Decision
Speaker
Template
Storage
Logic
2
4
8
6
Fig. 1: Possible attack locations in a typical ASV system. 1: microphone point,
2: transmission point, 3: override feature extractor, 4: modify probe to features, 5:
override classiﬁer, 6: modify speaker database, 7: modify biometric reference, 8:
modify score and 9: override decision.
given a speech signal, S, PA detection here, the determination of whether S is a
natural or PA speech can be formulated as a hypothesis test:
• H0: S is natural speech.
• H1: S is created with PA methods.
A can be applied to decide between H0 and H1. Suppose that X = {x1,x2,...,xN}
are the acoustic feature vectors of N speech frames extracted from S, then the loga-
rithmic likelihood ratio score is given by,
Λ(X) = log p(X|λH0)−log p(X|λH1)
(1)
In1, λH0 and λH1 are the acoustic models to characterise the hypotheses corre-
spondingly for natural speech and PA speech. The parameters of these models are
estimated using training data for natural and PA speech. A typical PAD system is
shown in Fig. 2. A test speech can be accepted as natural or rejected as PA speech
with help of a threshold, θ computed on some development data. If the score is
greater than or equal to the threshold, it is accepted; otherwise, rejected. The per-
formance of the PA system is assessed by computing the (EER) metric. This is the
error rate for a speciﬁc value of a threshold where two error rates, i.e., the proba-
bility of a PA speech detected as being natural speech (known as false acceptance
rate or FAR) and the probability of a natural speech speech being misclassiﬁed as a
PA speech (known as false rejection rate or FRR), are equal. Sometimes (HTER) is
also computed [7]. This is the average of FAR and FRR which are computed using
a decision threshold obtained with the help of the development data.
Awareness and acceptance of the vulnerability to PAs have generated a growing
interest in develop solutions to presentation attack detection (PAD), also referred to
as spooﬁng countermeasures. These are typically dedicated auxiliary systems which
function in tandem to ASV in order to detect and deﬂect PAs. The research in this
Authors Suppressed Due to Excessive Length
+
_
Feature
Extraction
Test Speech
Natural
Speech
Model
Speech
Model
PA
Natural
Speech
Speech
PA
Fig. 2: Block diagram of a typical presentation attack detection system.
direction has progressed rapidly in the last three years, due partly to the release of
several public speech corpora and the organisation of PAD challenges for ASV. This
article, a continuation of the chapter [8] in the ﬁrst edition of the Handbook for Bio-
metrics [9] presents an up-to-date review of the different forms of voice presentation
attacks, broadly classiﬁed in terms of impersonation, replay, speech synthesis and
voice conversion. The primary focus is nonetheless on the progress in PAD. The
chapter reviews the most recent work involving a variety of different features and
classiﬁers. Most of the work covered in the chapter relates to that conducted using
the two most popular and publicly available databases, which were used for the two
ASVspoof challenges co-organized by the authors. The chapter concludes with a
discussion of research challenges and future directions in PAD for ASV.
2 Basics of ASV spooﬁng and countermeasures
Spooﬁng or presentation attacks are performed on a biometric system at the sen-
sor or acquisition level to bias score distributions toward those of genuine clients,
thus provoking increases in the false acceptance rate (FAR). This section reviews
four well-known ASV spooﬁng techniques and their respective countermeasures:
impersonation, replay, speech synthesis and voice conversion. Here, we mostly re-
view the work in the pre-ASVspoof period, as well as some very recent studies on
presentation attacks.
2.1 Impersonation
In speech or mimicry attacks, an intruder speaker intentionally modiﬁes his or her
speech to sound like the target speaker. Impersonators are likely to copy lexical,
Introduction to Voice Presentation Attack Detection and Recent Advances
prosodic, and idiosyncratic behaviour of their target speakers presenting a potential
point of vulnerability concerning speaker recognition systems.
2.1.1 Spooﬁng
There are several studies about the consequences of mimicry on ASV. Some studies
concern attention to the voice modiﬁcations performed by professional imperson-
ators. It has been reported that impersonators are often particularly able to adapt the
fundamental frequency (F0) and occasionally also the formant frequencies towards
those of the target speakers [10, 11, 12]. In studies, the focus has been on analysing
the vulnerability of speaker veriﬁcation systems in the presence of voice mimicry.
The studies by Lau et al. [13, 14] suggest that if the target of impersonation is known
in advance and his or her voice is “similar” to the impersonator’s voice (in the sense
of automatic speaker recognition score), then the chance of spooﬁng an automatic
recognizer is increased. In [15], the experiments indicated that professional imper-
sonators are potentially better impostors than amateur or naive ones. Nevertheless,
the voice impersonation was not able to spoof the ASV system. In [10], the authors
attempted to quantify how much a speaker is able to approximate other speakers’
voices by selecting a set of prosodic and voice source features. Their prosodic and
acoustic based ASV results showed that two professional impersonators imitating
known politicians increased the identiﬁcation error rates.
More recently, a fundamentally different study was carried out by Panjwani et
al. [16] using crowdsourcing to recruit both amateur and more professional imper-
sonators. The results showed that impersonators succeed in increasing their average
score, but not in exceeding the target speaker score. All of the above studies anal-
ysed the effects of speech impersonation either at the acoustic or speaker recognition
score level, but none proposed any countermeasures against impersonation. In a re-
cent study [17], the experiments aimed to evaluate the vulnerability of three modern
speaker veriﬁcation systems against impersonation attacks and to further compare
these results to the performance of non-expert human listeners. It is observed that,
on average, the mimicry attacks lead to increased error rates. The increase in error
rates depends on the impersonator and the ASV system.
The main challenge, however, is that no large speech corpora of impersonated
speech exists for the quantitative study of impersonation effects on the same scale
as for other attacks, such as text-to-speech synthesis and voice conversion, where
generation of simulated spooﬁng attacks as well as developing appropriate counter-
measures is more convenient.
2.1.2 Countermeasures
While the threat of impersonation is not fully understood due to limited studies in-
volving small datasets, it is perhaps not surprising that there is no prior work investi-
gating countermeasures against impersonation. If the threat is proven to be genuine,
Authors Suppressed Due to Excessive Length
then the design of appropriate countermeasures might be challenging. Unlike the
spooﬁng attacks discussed below, all of which can be assumed to leave traces of
the physical properties of the recording and playback devices, or signal processing
artefacts from synthesis or conversion systems, impersonators are live human beings
who produce entirely natural speech.
2.2 Replay
attacks refer to the use of pre-recorded speech from a target speaker, which is then
replayed through some playback device to feed the system microphone. These at-
tacks require no speciﬁc expertise nor sophisticated equipment, thus they are easy
to implement. Replay is a relatively low-technology attack within the grasp of any
potential attacker even without specialised knowledge in speech processing. Several
works in the earlier literature report signiﬁcant increases in error rates when using
replayed speech. Even if replay attacks may present a genuine risk to ASV systems,
the use of prompted-phrase has the potential to mitigate the impact.
2.2.1 Spooﬁng
The study on the impact of replay attack on ASV performance was very limited
until recently before the release of AVspoof [18] and ASVspoof 2017 corpus. The
earlier studies were conducted either on simulated or on real replay recording from
far-ﬁeld.
The vulnerability of ASV systems to replay attacks was ﬁrst investigated in a
text-dependent scenario [19], where the concatenation of recorded digits was tested
against a hidden Markov model (HMM) based ASV system. Results showed an
increase in the FAR from 1 to 89% for male speakers and from 5 to 100% for female
speakers.
The work in [20] investigated text-independent ASV vulnerabilities through the
replaying of far-ﬁeld recorded speech in a mobile telephony scenario where signals
were transmitted by analogue and digital telephone channels. Using a baseline ASV
system based on joint factor analysis (JFA), the work showed an increase in the
EER of 1% to almost 70% when impostor accesses were replaced by replayed spoof
attacks.
A physical access scenario was considered in [21]. While the baseline perfor-
mance of the Gaussian mixture model- universal background model (GMM-UBM)
ASV system was not reported, experiments showed that replay attacks produced a
FAR of 93%.
The work in [18] introduced audio-visual spooﬁng (AVspoof) database for replay
attack detection where the replayed signals are collected and played back using dif-
ferent low-quality (phones and laptop) and high-quality (laptop with loud speakers)
devices. The study reported that FARs for replayed speech was 77.4% and 69.4%
Introduction to Voice Presentation Attack Detection and Recent Advances
for male and female, respectively, using a total variability system speaker recog-
nition system. In this study, the EER for bona ﬁde trials was 6.9% and 17.5% for
those conditions. This study also includes presentation attack where speech signals
created with voice conversion and speech synthesis were used in playback attack. In
that case, higher FAR was observed, particularly when high-quality device is used
for playback.
2.2.2 Countermeasures
A countermeasure for replay attack detection in the case of text-dependent ASV was
reported in [5]. The approach is based upon the comparison of new access samples
with stored instances of past accesses. New accesses which are deemed too simi-
lar to previous access attempts are identiﬁed as replay attacks. A large number of
different experiments, all relating to a telephony scenario, showed that the coun-
termeasures succeeded in lowering the EER in most of the experiments performed.
While some form of text-dependent or challenge-response countermeasure is usu-
ally used to prevent replay attacks, text-independent solutions have also been inves-
tigated. The same authors in [20] showed that it is possible to detect replay attacks
by measuring the channel differences caused by far-ﬁeld recording [22]. While they
show spoof detection error rates of less than 10% it is feasible that today’s state-
of-the-art approaches to channel compensation will render some ASV systems still
vulnerable.
Two different replay attack countermeasures are compared in [21]. Both are
based on the detection of differences in channel characteristics expected between
licit and spoofed access attempts. Replay attacks incur channel noise from both the
recording device and the loudspeaker used for replay and thus the detection of chan-
nel effects beyond those introduced by the recording device of the ASV system thus
serves as an indicator of replay. The performance of a baseline GMM-UBM system
with an EER of 40% under spooﬁng attack falls to 29% with the ﬁrst countermea-
sure and a more respectable EER of 10% with the second countermeasure.
In another study [23], a speech database of 175 subjects has been collected for
different kinds of replay attack. Other than the use of genuine voice samples for
the legitimate speakers in playback, the voice samples recorded over the telephone
channel were also used for unauthorised access. Further, a far-ﬁeld microphone is
used to collect the voice samples as eavesdropped (covert) recording. The authors
proposed an algorithm motivated from music recognition system used for compar-
ing recordings on the basis of the similarity of the local conﬁguration of maxima
pairs extracted from spectrograms of veriﬁed and reference recordings. The exper-
imental results show the EER of playback attack detection to be as low as 1.0% on
the collected data.
Authors Suppressed Due to Excessive Length
2.3 Speech synthesis
, commonly referred to as text-to-speech (TTS), is a technique for generating in-
telligible, natural sounding artiﬁcial speech for any arbitrary text. Speech synthesis
is used widely in various applications including in-car navigation systems, e-book
readers, voice-over for the visually impaired and communication aids for the speech
impaired. More recent applications include spoken dialogue systems, communica-
tive robots, singing speech synthesisers and speech-to-speech translation systems.
Typical speech synthesis systems have two main components [24]: text analysis
followed by speech waveform generation, which are sometimes referred to as the
front-end and back-end respectively. In the text analysis component, input text is
converted into a linguistic speciﬁcation consisting of elements such as phonemes.
In the speech waveform generation component, speech waveforms are generated
from the produced linguistic speciﬁcation. There are emerging end-to-end frame-
works that generate speech waveforms directly from text inputs without using any
additional modules.
Many approaches have been investigated, but there have been major paradigm
shifts every ten years. In the early 1970s, the speech waveform generation com-
ponent used very low dimensional acoustic parameters for each phoneme, such
as formants, corresponding to vocal tract resonances with hand-crafted acoustic
rules [25]. In the 1980s, the speech waveform generation component used a small
database of phoneme units called diphones (the second half of one phoneme plus the
ﬁrst half of the following) and concatenated them according to the given phoneme
sequence by applying signal processing, such as linear predictive (LP) analysis, to
the units [26]. In the 1990s, larger speech databases were collected and used to se-
lect more appropriate speech units that matched both phonemes and other linguistic
contexts such as lexical stress and pitch accent in order to generate high-quality
natural sounding synthetic speech with the appropriate prosody. This approach is
generally referred to as unit selection, and is nowadays used in many speech syn-
thesis systems [27, 28, 29, 30, 31].
In the late 2000s, several machine learning based data-driven approaches emerged.
‘Statistical parametric speech synthesis’ was one of the more popular machine learn-
ing approaches [32, 33, 34, 35]. In this approach, several acoustic parameters are
modelled using a time-series stochastic generative model, typically a HMM. HMMs
represent not only the phoneme sequences but also various contexts of the linguistic
speciﬁcation. Acoustic parameters generated from HMMs and selected according
to the linguistic speciﬁcation are then used to drive a vocoder, a simpliﬁed speech
production model in which speech is represented by vocal tract parameters and ex-
citation parameters in order to generate a speech waveform. HMM-based speech
synthesisers [36, 37] can also learn speech models from relatively small amounts of
speaker-speciﬁc data by adapting background models derived from other speakers
based on the standard model adaptation techniques drawn from speech recognition,
i.e., maximum likelihood linear regression (MLLR) [38, 39].
In the 2010s, deep learning has signiﬁcantly improved the performance of speech
synthesis and led to a signiﬁcant breakthrough. First, various types of deep neural
Introduction to Voice Presentation Attack Detection and Recent Advances
networks are used to improve the prediction accuracy of the acoustic parameters [40,
41]. Investigated architectures include recurrent neural network [42, 43, 44], resid-
ual/highway network [45, 46], autoregressive network [47, 48], and generative ad-
versarial networks (GAN) [49, 50, 51]. Furthermore, in the late 2010s conventional
waveform generation modules that typically used signal processing and text analy-
sis modules that used natural language processing were substituted by neural net-
works. This allows for neural networks capable of directly outputting the desired
speech waveform samples from the desired text inputs. Successful architectures for
direct waveform modelling include dilated convolutional autoregressive neural net-
work, known as “Wavenet” [52] and hierarichical recurrent neural network, called
“SampleRNN” [53]. Finally, we have also seen successful architectures that totally
remove the hand-crafted linguistic features obtained through text analysis by relying
in sequence-to-sequence systems. This system is called Tacotron [54]. As expected,
the combination of these advanced models results in a very high-quality end-to-end
TTS synthesis system [55, 56] and recent results reveal that the generated synthetic
speech sounds as natural as human speech [56].
For more details and technical comparisons, please see the results of Blizzard
Challenge, which annually compares the performance of speech synthesis systems
built on the common database over decades [57, 58].
2.3.1 Spooﬁng
There is a considerable volume of research in the literature which has demonstrated
the vulnerability of ASV to synthetic voices generated with a variety of approaches
to speech synthesis. Experiments using formant, diphone, and unit-selection based
synthetic speech in addition to the simple cut-and-paste of speech waveforms have
been reported [19, 59, 20].
ASV vulnerabilities to HMM-based synthetic speech were ﬁrst demonstrated
over a decade ago [60] using an HMM-based, text-prompted ASV system [61] and
an HMM-based synthesiser where acoustic models were adapted to speciﬁc hu-
man speakers [62, 63]. The ASV system scored feature vectors against speaker and
background models composed of concatenated phoneme models. When tested with
human speech, the ASV system achieved a FAR of 0% and a false rejection rate
(FRR) of 7%. When subjected to spooﬁng attacks with synthetic speech, the FAR
increased to over 70%, however, this work involved only 20 speakers.
Larger scale experiments using the Wall Street Journal corpus containing in the
order of 300 speakers and two different ASV systems (GMM-UBM and SVM using
Gaussian supervectors) was reported in [64]. Using an HMM-based speech synthe-
siser, the FAR was shown to rise to 86% and 81% for the GMM-UBM and SVM sys-
tems respectively representing a genuine threat to ASV. Spooﬁng experiments using
HMM-based synthetic speech against a forensics speaker veriﬁcation tool BATVOX
was also reported in [65] with similar ﬁndings. Therefore, the above speech synthe-
sisers were chosen as one of spooﬁng methods in the ASVspoof 2015 database.
Authors Suppressed Due to Excessive Length
Spooﬁng experiments using the above advanced DNNs or using spooﬁng-speciﬁc
strategies such as GAN have not yet been properly investigated. Only a rela-
tively small-scale spooﬁng experiment against a speaker recognition system using
Wavenet, SampleRNN and GAN is reported in [66].
2.3.2 Countermeasures
Only a small number of attempts to discriminate synthetic speech from natural
speech had been investigated before the ASVspoof challenge started. Previous work
has demonstrated the successful detection of synthetic speech based on prior knowl-
edge of the acoustic differences of speciﬁc speech synthesizers, such as the dynamic
ranges of spectral parameters at the utterance level [67] and variance of higher order
parts of mel-cepstral coefﬁcients [68].
There are some attempts which focus on acoustic differences between vocoders
and natural speech. Since the human auditory system is known to be relatively in-
sensitive to phase [69], vocoders are typically based on a minimum-phase vocal tract
model. This simpliﬁcation leads to differences in the phase spectra between human
and synthetic speech, differences which can be utilised for discrimination [64, 70].
Based on the difﬁculty in reliable prosody modelling in both unit selection and
statistical parametric speech synthesis, other approaches to synthetic speech detec-
tion use F0 statistics [71, 72]. F0 patterns generated for the statistical parametric
speech synthesis approach tend to be over-smoothed and the unit selection approach
frequently exhibits ‘F0 jumps’ at concatenation points of speech units.
After the ASVspoof challenges took place, various types of countermeasures that
work for both speech synthesis and voice conversion have been proposed. Please
read the next section for the details of the recently developed countermeasures.
2.4 Voice conversion
, in short, VC , is a spooﬁng attack against automatic speaker veriﬁcation using
an attackers natural voice which is converted towards that of the target. It aims to
convert one speaker’s voice towards that of another and is a sub-domain of voice
transformation [73]. Unlike TTS, which requires text input, voice conversion oper-
ates directly on speech inputs. However, speech waveform generation modules such
as vocoders, may be the same as or similar to those for TTS.
A major application of VC is to personalise and create new voices for TTS syn-
thesis systems and spoken dialogue systems. Other applications include speaking
aid devices that generate more intelligible voice sounds to help people with speech
disorders, movie dubbing, language learning, and singing voice conversion. The
ﬁeld has also attracted increasing interest in the context of ASV vulnerabilities for
almost two decades [74].
Introduction to Voice Presentation Attack Detection and Recent Advances
Most voice conversion approaches require a parallel corpus where source and tar-
get speakers read out identical utterances and adopt a training phase which typically
requires frame- or phone-aligned audio pairs of the source and target utterances and
estimates transformation functions that convert acoustic parameters of the source
speaker to those of the target speaker. This is called “parallel voice conversion”.
Frame alignment is traditionally achieved using dynamic time warping (DTW) on
the source-target training audio ﬁles. Phone alignment is traditionally achieved us-
ing automatic speech recognition (ASR) and phone-level forth alignment. The es-
timated conversion function is then applied to any new audio ﬁles uttered by the
source speaker [75].
A large number of estimation methods for the transformation functions have been
reported starting in the late 1980s. In the late 1980’s and 90’s, simple techniques em-
ploying vector quantisation (VQ) with codebooks [76] or segmental codebooks [77]
of paired source-target frame vectors were proposed to represent the transforma-
tion functions. However, these VQ methods introduced frame-to-frame discontinu-
ity problems.
In the late 1990s and 2000s, joint density Gaussian mixture model (JDGMM)
based transformation methods [78, 79] were proposed and have since then been
actively improved by many researchers [80, 81]. This method still remains popular
even now. Although this method achieves smooth feature transformations using a
locally linear transformation, this method also has several critical problems such as
over-smoothing [82, 83, 84] and over-ﬁtting [85, 86] which leads to mufﬂed quality
of speech and degraded speaker similarity.
Therefore, in the early 2010, several alternative linear transformation methods
were developed. Examples are partial least square (PLS) regression [85], tensor
representation [87], a trajectory HMM [88], mixture of factor analysers [89], local
linear transformation [82] or noisy channel models [90].
In parallel to the linear-based approaches, there have been studies on non-
linear transformation functions such as support vector regression [91], kernel partial
least square [92], and conditional restricted Boltzmann machines [93], neural net-
works [94, 95], highway network [96], and RNN [97, 98]. Data-driven frequency
warping techniques [99, 100, 101] have also been studied.
Recently, deep learning has changed the above standard procedures for voice
conversion and we can see many different solutions now. For instance, variational
auto-encoder or sequence-to-sequence neural networks enable us to build VC sys-
tems without using frame level alignment [102, 103]. It has also been showed that a
cycle-consistent adversarial network called “CycleGAN” [104] is one possible so-
lution for building VC systems without using a parallel corpus. Wavenet can also be
used as a replacement for the purpose of generating speech waveforms from con-
verted acoustic features [105].
The approaches to voice conversion considered above are usually applied to the
transformation of spectral envelope features, though the conversion of prosodic fea-
tures such as fundamental frequency [106, 107, 108, 109] and duration [107, 110]
has also been studied.
Authors Suppressed Due to Excessive Length
For more details and technical comparisons, please see results of Voice Conver-
sion Challenges that compare the performance of VC systems built on a common
database [111, 112].
2.4.1 Spooﬁng
When applied to spooﬁng, the aim with voice conversion is to synthesise a new
speech signal such that the extracted ASV features are close in some sense to the tar-
get speaker. Some of the ﬁrst works relevant to text-independentASV spooﬁng were
reported in [113, 114]. The work in [113] showed that baseline EER increased from
16% to 26% thanks to a voice conversion system which also converted prosodic
aspects not modeled in typical ASV systems. This work targeted the conversion
of spectral-slope parameters and showed that the baseline EER of 10% increased
to over 60% when all impostor test samples were replaced with converted voices.
Moreover, signals subjected to voice conversion did not exhibit any perceivable arte-
facts indicative of manipulation.
The work in [115] investigated ASV vulnerabilities to voice conversion based
on JDGMMs [78] which requires a parallel training corpus for both source and tar-
get speakers. Even if the converted speech could be easily detectable by human
listeners, experiments involving ﬁve different ASV systems showed their universal
susceptibility to spooﬁng. The FAR of the most robust, JFA system increased from
3% to over 17%. Instead of vocoder-based waveform generation, unit selection ap-
proaches can be applied directly to feature vectors coming from the target speaker
to synthesise converted speech [116]. Since they use target speaker data directly,
unit-selection approaches arguably pose a greater risk to ASV than statistical ap-
proaches [117]. In the ASVspoof 2015 challenge, we therefore had chosen these
popular VC methods as spooﬁng methods.
Other work relevant to voice conversion includes attacks referred to as artiﬁcial
signals. It was noted in [118] that certain short intervals of converted speech yield
extremely high scores or likelihoods. Such intervals are not representative of intelli-
gible speech but they are nonetheless effective in overcoming typical ASV systems
which lack any form of speech quality assessment. The work in [118] showed that
artiﬁcial signals optimised with a genetic algorithm provoke increases in the EER
from 10% to almost 80% for a GMM-UBM system and from 5% to almost 65% for
a factor analysis (FA) system.
2.4.2 Countermeasures
Here, we provide an overview of countermeasure methods developed for the VC
attacks before the ASVspoof challenge began.
Some of the ﬁrst works to detect converted voice draws on related work in syn-
thetic speech detection [119]. In [70, 120], cosine phase and modiﬁed group delay
function (MGDF) based countermeasures were proposed. These are effective in de-
Introduction to Voice Presentation Attack Detection and Recent Advances
tecting converted speech using vocoders based on minimum phase. In VC, it is,
however, possible to use natural phase information extracted from a source speaker
[114]. In this case, they are unlikely to detect converted voice.
Two approaches to artiﬁcial signal detection are reported in [121]. Experimen-
tal work shows that supervector-based SVM classiﬁers are naturally robust to such
attacks, and that all the spooﬁng attacks they used could be detected by using an
utterance-level variability feature, which detected the absence of the natural and dy-
namic variabilities characteristic of genuine speech. A related approach to detect
converted voice is proposed in [122]. Probabilistic mappings between source and
target speaker models are shown to typically yield converted speech with less short-
term variability than genuine speech. Therefore, the thresholded, average pair-wise
distance between consecutive feature vectors was used to detect converted voice
with an EER of under 3%.
Due to fact that majority of VC techniques operate at the short-term frame level,
more sophisticated long-term features such as temporal magnitude and phase mod-
ulation feature can also detect converted speech [123]. Another experiment reported
in [124] showed that local binary pattern analysis of sequences of acoustic vectors
can also be used for successfully detecting frame-wise JDGMM-based converted
voice. However, it is unclear whether these features are effective in detecting recent
VC systems that consider long-term dependency such as recurrent or autoregressive
neural network models.
After the ASVspoof challenges took place, new countermeasures that works for
both speech synthesis and voice conversion were proposed and evaluated. See the
next section for a detailed review of the recently developed countermeasures.
3 Summary of the spooﬁng challenges
A number of independent studies conﬁrm the vulnerability of ASV technology to
spoofed voice created using voice conversion, speech synthesis, and playback [6].
Early studies on speaker anti-spooﬁng were mostly conducted on in-house speech
corpora created using a limited number of spooﬁng attacks. The development of
countermeasures using only a small number of spooﬁng attacks may not offer the
generalisation ability in the presence of different or unseen attacks. There was a
lack of publicly available corpora and evaluation protocol to help with comparing
the results obtained by different researchers.
The 1 initiative aims to overcome this bottleneck by making available standard
speech corpora consisting of a large number of spooﬁng attacks, evaluation proto-
cols, and metrics to support a common evaluation and the benchmarking of different
systems. The speech corpora were initially distributed by organising an evaluation
challenge. In order to make the challenge simple and to maximise participation,
the ASVspoof challenges so far involved only the detection of spoofed speech; in
1 http://www.asvspoof.org/
Authors Suppressed Due to Excessive Length
effect, to determine whether a speech sample is genuine or spoofed. A training set
and development set consisting of several spooﬁng attacks were ﬁrst shared with the
challenge participants to help them develop and tune their anti-spooﬁng algorithm.
Next, the evaluation set without any label indicating genuine or spoofed speech was
distributed, and the organisers asked the participants to submit scores within a spe-
ciﬁc deadline. Participants were allowed to submit scores of multiple systems. One
of these systems was designated as the primary submission. Spooﬁng detectors for
all primary submissions were trained using only the training data in the challenge
corpus. Finally, the organisers evaluated the scores for benchmarks and ranking.
The evaluation keys were subsequently released to the challenge participants. The
challenge results were discussed with the participants in a special session in IN-
TERSPEECH conferences, which also involved sharing knowledge and receiving
useful feedback. To promote further research and technological advancements, the
datasets used in the challenge are made publicly available.
The ASVspoof challenges have been organised twice so far. The ﬁrst was held
in 2015 and the second in 2017. A summary of the speech corpora used in the two
challenges are shown in Table 1. In both the challenges, EER metric was used to
evaluate the performance of spooﬁng detector. The EER is computed by considering
the scores of genuine ﬁles as positive scores and those of spoofed ﬁles as negative
scores. A lower EER means more accurate spooﬁng countermeasures. In practice,
the EER is estimated using a speciﬁc receiver operating characteristics convex hull
(ROCCH) technique with an open-source implementation2 originating from outside
the ASVspoof consortium. In the following subsections, we brieﬂy discuss the two
challenges. For more interested readers, [125] contains details of the 2015 edition
while [126] discusses the results of the 2017 edition.
3.1 ASVspoof 2015
The ﬁrst ASVspoof challenge involved detection of artiﬁcial speech created using a
mixture of voice conversion and speech synthesis techniques [125]. The dataset was
generated with ten different artiﬁcial speech generation algorithms. The was based
upon a larger collection spooﬁng and anti-spooﬁng (SAS) corpus (v1.0) [127] that
consists of both natural and artiﬁcial speech. Natural speech was recorded from 106
human speakers using a high-quality microphone and without signiﬁcant channel or
background noise effects. In a speaker disjoint manner, the full database was divided
into three subsets called the training, development, and evaluation set. Five of the
attacks (S1-S5), named as known attacks, were used in the training and development
set. The other ﬁve attacks, S6-S10, called unknown attacks, were used only in the
evaluation set, along with the known attacks. Thus, this provides the possibility of
assessing the generalisability of the spooﬁng detectors. The detailed evaluation plan
is available in [128], describing the speech corpora and challenge rules.
2 https://sites.google.com/site/bosaristoolkit/
Introduction to Voice Presentation Attack Detection and Recent Advances
Table 1: Summary of the datasets used in ASVspoof challenges.
ASVspoof 2015 [125]
ASVspoof 2017 [126]
Theme
Detection of artiﬁcially generated speech
Detection of replay speech
Speech format
Fs = 16 kHz, 16 bit PCM
Fs = 16 kHz, 16 bit PCM
Natural speech
Recorded using high-quality microphone
Recorded using different smart phones
Spoofed speech
Created with seven VC
Collected ‘in the wild’ by crowdsourcing
and three SS methods
using different microphone and playback
devices from diverse environments
Spooﬁng types
5 / 5 / 10
3 / 10 / 57
in train/dev/eval
No of speakers
25 / 35 / 46
10 / 8 / 24
in train/dev/eval
No of genuine speech
3750 / 3497 / 9404
1508 / 760 / 1298
ﬁles in train/dev/eval
No of spoofed speech
12625 / 49875 / 184000
1508 / 950 / 12008
ﬁles in train/dev/eval
Ten different spooﬁng attacks used in the ASVspoof 2015 are listed below:-
• S1: a simpliﬁed frame selection (FS) based voice conversion algorithm, in
which the converted speech is generated by selecting target speech frames.
• S2: the simplest voice conversion algorithm which adjusts only the ﬁrst mel-
cepstral coefﬁcient (C1) in order to shift the slope of the source spectrum to the
target.
• S3: a speech synthesis algorithm implemented with the HMM based speech
synthesis system (HTS3) using speaker adaptation techniques and only 20 adap-
tation utterances.
• S4: the same algorithm as S3, but using 40 adaptation utterances.
• S5: a voice conversion algorithm implemented with the voice conversion toolkit
and with the Festvox system3.
• S6: a VC algorithm based on joint density Gaussian mixture models (GMMs)
and maximum likelihood parameter generation considering global variance.
• S7: a VC algorithm similar to S6, but using line spectrum pair (LSP) rather than
mel-cepstral coefﬁcients for spectrum representation.
• S8: a tensor-based approach to VC, for which a Japanese dataset was used to
construct the speaker space.
• S9: a VC algorithm which uses kernel-based partial least square (KPLS) to
implement a non-linear transformation function.
• S10: an SS algorithm implemented with the open-source MARY text-to-tpeech
system (MaryTTS)4.
3 http://www.festvox.org/
4 http://mary.dfki.de/
Authors Suppressed Due to Excessive Length
Table 2: Performance of top ﬁve systems in ASVspoof 2015 challenge (ranked ac-
cording to the average % EER for all attacks) with respective features and classiﬁers.
System
Avg. EER for
System
Identiﬁer known unknown
all
Description
A [129]
0.408
2.013
1.211
Features: mel-frequency cepstral coefﬁcients (MFCC),
Cochlear ﬁlter cepstral coefﬁcients plus instantaneous frequency (CFCCIF).
Classiﬁer: GMM.
B [130]
0.008
3.922
1.965
Features: MFCC, MFPC,
cosine-phase principal coefﬁcients (CosPhasePCs).
Classiﬁer: Support vector machine (SVM) with i-vectors.
C [131]
0.058
4.998
2.528
Feature: DNN-based with ﬁlterbank output and their deltas as input.
Classiﬁer: Mahalanobis distance on s-vectors.
D [132]
0.003
5.231
2.617
Features: log magnitude spectrum (LMS),
residual log magnitude spectrum (RLMS), group delay (GD),
modiﬁed group delay (MGD), instantaneous frequency derivative (IF),
baseband phase difference (BPD), and pitch synchronous phase (PSP).
Classiﬁer: Multilayer perceptron (MLP).
E [133]
0.041
5.347
2.694
Features: MFCC, product spectrum MFCC (PS-MFCC),
MGD with and without energy, weighted linear prediction group delay
cepstral coefﬁcients (WLP-GDCCs), and MFCC
cosine-normalised phase-based cepstral coefﬁcients (MFCC-CNPCCs).
Classiﬁer: GMM.
More details of how the SAS corpus was generated can be found in [127].
The organisers also conﬁrmed the vulnerability to spooﬁng by conducting speaker
veriﬁcation experiments with this data and demonstrating considerable performance
degradation in the presence of spooﬁng. With a state-of-the-art probabilistic linear
discriminant analysis (PLDA) based ASV system, it is shown that in presence of
spooﬁng, the average EER for ASV increases from 2.30% to 36.00% for male and
2.08% to 39.53% for female [125]. This motivates the development of the anti-
spooﬁng algorithm.
For ASVspoof 2015, the challenge evaluation metric was the average EER. It is
computed by calculating EERs for each attack and then taking average. The dataset
was requested by 28 teams from 16 countries, 16 teams returned primary submis-
sions by the deadline. A total of 27 additional submissions were also received.
Anonymous results were subsequently returned to each team, who were then invited
to submit their work to the ASVspoof special session for INTERSPEECH 2015.
Table 2 shows the performance of the top ﬁve systems in the ASVspoof 2015
challenge. The best performing system [129] uses a combination of mel cesptral
and cochlear ﬁlter cepstral coefﬁcients plus instantaneous frequency features with
GMM back-end. In most cases, the participants have used fusion of multiple fea-
ture based systems to get better recognition accuracy. Variants of cepstral features
computed from the magnitude and phase of short-term speech are widely used for
Introduction to Voice Presentation Attack Detection and Recent Advances
the detection of spooﬁng attacks. As a back-end, GMM was found to outperform
more advanced classiﬁers like i-vectors, possibly due to the use of short segments
of high-quality speech not requiring treatment for channel compensation and back-
ground noise reduction. All the systems submitted in the challenge are reviewed in
more detail [134].
3.2 ASVspoof 2017
The is the second automatic speaker veriﬁcation antispooﬁng and countermeasures
challenge. Unlike the 2015 edition that used very high-quality speech material, the
2017 edition aims to assess spooﬁng attack detection with ”out in the wild” condi-
tions. It focuses exclusively on replay attacks. The corpus originates from the recent
text-dependent RedDots corpus5, whose purpose was to collect speech data over mo-
bile devices, in the form of smartphones and tablet computers, by volunteers from
across the globe.
The replayed version of the original RedDots corpus was collected through a
crowdsourcing exercise using various replay conﬁgurations consisting of varied de-
vices, loudspeakers, and recording devices, under a variety of different environ-
ments across four European countries within the EU Horizon 2020-fundedOCTAVE
project6, (see [126]). Instead of covert recording, we made a “short-cut” and took
the digital copy of the target speakers’ voice to create the playback versions. The
collected corpus is divided into three subsets: for training, development, and eval-
uation. Details of each are presented in Table 1. All three subsets are disjoint in
terms of speakers and data collection sites. The training and development subsets
were collected at three different sites. The evaluation subset was collected at the
same three sites and also included data from two new sites. Data from the same site
include different recordings and replaying devices and from different acoustic envi-
ronments. The evaluation subset contains data collected from 161 replay sessions in
62 unique replay conﬁgurations7. More details regarding replay conﬁgurations can
be found in [126, 135].
The primary evaluation metric is “pooled” EER. In contrast to the ASVspoof
2015 challenge, the EER is computed from scores pooled across all the trial seg-
ments rather than condition averaging. A baseline8 system based on common GMM
back-end classiﬁer with constant Q cepstral coefﬁcient (CQCC) [136, 137] features
was provided to the participants. This conﬁguration is chosen as baseline as it has
shown best recognition performance on ASVspoof 2015. The baseline is trained
using either combined training and development data (B01) or training data (B02)
alone. The baseline system does not involve any kind of optimisation or tuning with
5 https://sites.google.com/site/thereddotsproject/
6 https://www.octave-project.eu/
7 A replay conﬁguration refers to a unique combination of room, replay device and recording
device while a session refers to a set of source ﬁles, which share the same replay conﬁguration.
8 See Appendix A.2. Software packages
Authors Suppressed Due to Excessive Length
6.73 
12.34 
14.03 
14.66 
15.97 
17.62 
18.14 
18.32 
20.32 
20.57 
21.11 
21.51 
21.98 
22.17 
22.39 
22.79 
23.16 
23.24 
23.29 
23.78 
24.77 
24.88 
24.94 
25.41 
26.58 
26.69 
27.16 
27.63 
27.68 
27.72 
28.42 
28.63 
28.63 
29.36 
30.42 
30.55 
30.60 
31.00 
31.15 
31.63 
32.35 
32.71 
34.78 
35.57 
36.49 
37.27 
38.17 
39.07 
39.39 
45.55 
7.00 
5
15
25
35
45
S01
S02
S03
S04
S05
S06
S07
S08
S10
S09
S11
S12
S13
S14
S15
S16
S19
S18
S17
S20
B01
S21
S22
S23
S24
S25
S26
S28
S27
S29
S30
S31
S32
S33
S34
S35
B02
S36
S38
S37
S39
S40
S41
S42
S43
S44
S45
S46
S47
S48
D01
Equal error rate (EER, in %) 
System ID 
Fig. 3: Performance of the two baseline systems (B01 and B02) and the 49 primary
systems (S01—S48 in addition to late submission D01) for the ASVspoof 2017
challenge. Results are in terms of the replay/non-replay EER (%).
respect to [136]. The dataset was requested by 113 teams, of which 49 returned pri-
mary submissions by the deadline. The results of the challenge were disseminated
at a special session consisting of two slots at INTERSPEECH 2017.
Most of the systems are based on standard spectral features, such as CQCCs,
MFCCs, and perceptual linear prediction (PLP). As a back-end, in addition to the
classical GMM to model the replay and non-replay classes, it has also exploited the
power of deep classiﬁers, such as convolutional neural network (CNN) or recurrent
neural network (RNN). A fusion of multiple features and classiﬁers is also widely
adopted by the participants. A summary of the top-10 primary systems is provided
in Table 3. Results in terms of EER of the 49 primary systems and the baseline B01
and B02 are shown in Figure 3.
4 Advances in front-end features
The selection of appropriate features for a given classiﬁcation problem is an im-
portant task. Even if the classic boundary to think between a feature extractor
(front-end) and a classiﬁer (back-end) as separate components is getting increas-
ingly blurred with the use of end-to-end deep learning and other similar techniques,
research on the ‘early’ components in a pipeline remains important. In the context
of anti-spooﬁng for ASV, this allows the utilisation of one’s domain knowledge to
guide the design of new discriminative features. For instance, earlier experience
suggests that lack of spectral [70] and temporal [123] detail is characteristic of syn-
thetic or voice-coded (vocoded) speech, and that low-quality replayed signals tend
to experience loss of spectral details [143]. These initial ﬁndings sparked further re-
search into developing advanced front-end features with improved robustness, gen-
eralisation across datasets, and other desideratum. As a matter of fact, in contrast
to classic ASV (without spooﬁng attacks) where the most signiﬁcant advancements
Introduction to Voice Presentation Attack Detection and Recent Advances
Table 3: Summary of top 10 primary submissions to ASVspoof 2017. Systems’ IDs
are the same received by participants in the evaluation. The column ‘Training’ refers
to the part of data used for training: train (T) and/or development (D).
ID
Features
Post-
proc.
Classiﬁers
Fusion
#Subs.
Training
Performances
on eval subset
(EER%)
S01 [138]
Log-power
Spec-
trum, LPCC
MVN
CNN, GMM, TV, RNN
Score
T
6.73
S02 [139]
CQCC, MFCC, PLP WMVN
GMM-UBM, TV-PLDA,
GSV-SVM, GSV-GBDT,
GSV-RF
Score
–
T
12.34
S03
MFCC,
IMFCC,
RFCC, LFCC, PLP,
CQCC,
SCMC,
SSFC
–
GMM, FF-ANN
Score
T+D
14.03
S04
RFCC, MFCC, IM-
FCC, LFCC, SSFC,
SCMC
–
GMM
Score
T+D
14.66
S05 [140]
Linear
ﬁlterbank
feature
MN
GMM, CT-DNN
Score
T
15.97
S06
CQCC,
IMFCC,
SCMC,
Phrase
one-hot encoding
MN
GMM
Score
T+D
17.62
S07
HPCC, CQCC
MVN
GMM, CNN, SVM
Score
T+D
18.14
S08 [141]
IFCC,
CFCCIF,
Prosody
–
GMM
Score
T
18.32
S09
SFFCC
No
GMM
None
T
20.57
S10 [142]
CQCC
–
ResNet
None
T
20.32
have been in the back-end modelling [2], in ASV anti-spooﬁng, the features seem
to make the difference. In this section, we take a brief look at a few such methods
emerging from the ASVspoof evaluations. The list is by no means exhaustive and
the interested reader is referred to [134] for further discussion.
4.1 Front-ends for detection of voice conversion and speech
synthesis spooﬁng
The front-ends described below have been shown to provide good performance on
the ASVspoof 2015 database of spooﬁng attacks based on voice conversion and
speech synthesis. The ﬁrst front-end was used in the ASVspoof 2015 challenge,
while the rest were proposed later after the evaluation.
Cochlear ﬁlter cepstral coefﬁcients with instantaneous frequency (CFC-
CIF). These features were introduced in [129] and successfully used as part of the
top-ranked system in the ASVspoof 2015 evaluation. They combine cochlear ﬁlter
cepstral coefﬁcients (CFCC), proposed in [144], with instantaneous frequency [69].
CFCC are based on wavelet transform-like auditory transform and on some mech-
Authors Suppressed Due to Excessive Length
anisms of the cochlea of the human ear, such as hair cells and nerve spike den-
sity. To compute CFCC with instantaneous frequency (CFCCIF), the output of the
nerve spike density envelope is multiplied by the instantaneous frequency, followed
by the derivative operation and logarithm non-linearity. Finally, the discrete cosine
transform (DCT) is applied to decorrelate the features and obtain a set of cepstral
coefﬁcients.
Linear frequency cepstral coefﬁcients (LFCC). LFCCs are very similar to the
widely used mel-frequency cepstral coefﬁcients (MFCCs) [145], though the ﬁlters
are placed in equal sizes for linear scale. This front-end is widely used in speaker
recognition and has been shown to perform well in spooﬁng detection [146]. This
technique performs a windowing on the signal, computes the magnitude spectrum
using the short-time Fourier transform (STFT), followed by logarithm non-linearity
and the application of a ﬁlterbank of linearly-spaced N triangular ﬁlters to obtain a
set of N log-density values. Finally, the DCT is applied to obtain a set of cepstral
coefﬁcients.
Constant Q cepstral coefﬁcients (CQCC). This feature was proposed in [136,
137] for spooﬁng detection and it is based on the constant Q transform (CQT) [147].
The CQT is an alternative time-frequency analysis tool to the STFT that provides
variable time and frequency resolution. It provides greater frequency resolution at
lower frequencies but greater time resolution at higher frequencies. Figure 4 illus-
trates the extraction process. The CQT spectrum is obtained, followed by logarithm
non-linearity and by a linearisation of the CQT geometric scale. Finally, cepstral
coefﬁcients are obtained though the DCT.
Fig. 4: Block diagram of CQCC feature extraction process.
As an alternative to CQCC, inﬁnite impulse response constant-Q transform cep-
strum (ICQC) features [148] use the inﬁnite impulse response - constant Q trans-
form [149], an efﬁcient constant Q transform based on the IIR ﬁltering of the fast
Fourier transform (FFT) spectrum. It delivers multiresolution time-frequency anal-
ysis in a linear scale spectrum which is ready to be coupled with traditional cepstral
analysis. The IIR-CQT spectrum is followed by the logarithm and decorrelation,
either through the DCT or principal component analysis.
Deep features for spooﬁng detection. All of the above three features sets are
hand-crafted and consists of a ﬁxed sequence of standard digital signal processing
operations. An alternative approach, seeing increased popularity across different
machine learning problems, is to learn the feature extractor from a given data by
using deep learning techniques [150, 151]. In speech-related applications, these fea-
tures are widely employed for improving recognition accuracy [152, 153, 154]. The
work in [155] uses deep neural network to generate bottleneck features for spooﬁng
Introduction to Voice Presentation Attack Detection and Recent Advances
detection; that is, the activations of a hidden layer with a relatively small number of
nodes compared to the size of other layers. The study in [156] investigates various
features based on deep learning techniques. Different feed-forward DNNs are used
to obtain frame-level deep features. Input acoustic features consisting of ﬁlterbank
outputs with their ﬁrst derivatives are used to train the network to discriminate be-
tween the natural and spoofed speech classes, and output of hidden layers are taken
as deep features which are then averaged to obtain an utterance-level descriptor.
RNNs are also proposed to estimate utterance-level features from input sequences
of acoustic features. In another recent work [157], the authors have investigated
deep features based on ﬁlterbank trained with the natural and artiﬁcial speech data.
A feed forward neural network architecture called here as ﬁlterbank neural network
(FBNN) is used here that includes a linear hidden layer, a sigmoid hidden layer and
a softmax output layer. The number of nodes in the output is six; and of them, ﬁve
are for the number of spoofed classes in the training set, and the remaining one is for
natural speech. The ﬁlterbanks are learned using the stochastic gradient descent al-
gorithm. The cepstral features extracted using these DNN-based features are shown
to be better than the hand-crafted cepstral coefﬁcients.
Scattering cepstral coefﬁcients. This feature for spooﬁng detection was pro-
posed in [158]. It relies upon scattering spectral decomposition [159, 160]. This
transform is a hierarchical spectral decomposition of a signal based on wavelet ﬁlter-
banks (constant Q ﬁlters), modulus operator, and averaging. Each level of decompo-
sition processes the input signal (either the input signal for the ﬁrst level of decom-
position, or the output of a previous level of decomposition) through the wavelet
ﬁlterbank and takes the absolute value of ﬁlter outputs, producing a scalogram. The
scattering coefﬁcients at a certain level are estimated by windowing the scalogram
signals and computing the average value within these windows. A two-level scat-
tering decomposition has been shown to be effective for spooﬁng detection [158].
The ﬁnal feature vector is computed by taking the DCT of the vector obtained by
concatenating the logarithms of the scattering coefﬁcients from all levels and retain-
ing the ﬁrst a few coefﬁcients. The “interesting” thing about scattering transform is
its stability to small signal deformation and more details of the temporal envelopes
than MFCCs [159, 158].
Fundamental frequency variation features. The prosodic features are not as
successful as cepstral features in detecting artiﬁcial speech on ASVspoof 2015,
though some earlier results on PAs indicate that pitch contours are useful for such
tasks [6]. In a recent work [161], the author use fundamental frequency varia-
tion (FFV) for this. The FFV captures pitch variation at the frame-level and pro-
vides complementary information on cepstral features [162]. The combined system
gives a very promising performance for both known and unknown conditions on
ASVspoof evaluation data.
Phase-based features. The phase-based features are also successfully used in
PAD systems for ASVspoof 2015. For example, relative phase shift (RPS) and
modiﬁed group delay (MGD) based features are explored in [163]. The authors
in [164] have investigated relative phase information (RPI) features. Though the
Authors Suppressed Due to Excessive Length
performances on seen attacks are promising with these phase-based features, the
performances noticeably degrade for unseen attacks, particularly for S10.
General observations regarding front-ends for artiﬁcial speech detection.
Beyond the feature extraction method used, there are two general ﬁndings com-
mon to any front end [146, 129, 137, 148]. The ﬁrst refers to the use of dynamic
coefﬁcients. The ﬁrst and second derivatives of the static coefﬁcients, also known as
velocity and acceleration coefﬁcients, respectively are found important to achieve
good spooﬁng detection performance. In some cases, the use of only dynamic fea-
tures is superior to the use of static plus dynamic coefﬁcients [146]. This is not en-
tirely surprising, since voice conversion and speech synthesis techniques may fail to
model the dynamic properties of the speech signals, introducing artefacts that help
the discrimination of spoofed signals. The second ﬁnding refers to the use of speech
activity detection. In experiments with ASVspoof 2015 corpus, it appears that the
silence regions also contain useful information for discriminating between natural
and synthetic speech. Thus, retaining non-speech frames turns out to be a better
choice for this corpus [146]. This is likely due to the fact that non-speech regions
are usually replaced with noise during the voice conversion or speech synthesis
operation. However, this could be a database-dependent observation, thus detailed
investigations are required.
4.2 Front-ends for replay attack detection
The following front-ends have been proposed for the task of replay spooﬁng de-
tection, and evaluated in replayed speech databases such as the BTAS 2016 and
ASVspoof 2017. Many standard front-ends, such as MFCC, LFCC, and PLP, have
been combined to improve the performance of replay attack detection. Other front-
ends proposed for synthetic and converted speech detection (CFCCIF, CQCC) have
been successfully used for the replay detection task. In general, and in opposition
to the trend for synthetic and converted speech detection, the use of static coef-
ﬁcients has been shown to be crucial for achieving good performance. This may
be explained by the nature of the replayed speech detection task, where detecting
changes in the channel captured by static coefﬁcients helps with the discrimination
of natural and replayed speech. Two additional front-ends are described next.
Inverted mel frequency cepstral coefﬁcients (IMFCC). This front-end is rel-
atively simple and similar to the standard MFCC. The only difference is that the
ﬁlterbank follows an inverted mel scale; that is, it provides an increasing frequency
resolution (narrower ﬁlters) when frequency increases, and a decreased frequency
resolution (wider ﬁlters) for decreasing frequency, unlike the mel scale [165]. This
front-end was used as part of the top-ranked system of the Biometrics: Theory, Ap-
plications, and Systems (BTAS) 2016 speaker antispooﬁng competition [7].
Features based on convolutional neural networks. In the recent ASVspoof
2017 challenge, the use of deep learning frameworks for feature learning was proven
to be key in achieving good replay detection performance. In particular, convolu-
Introduction to Voice Presentation Attack Detection and Recent Advances
tional neural networks have been successfully used to learn high-level utterance-
level features which can later be classiﬁed with simple classiﬁers. As part of the top-
ranked system [138] in the ASVspoof 2017 challenge, a light convolutional neural
network architecture [166] is fed with truncated normalised FFT spectrograms (to
force ﬁxed data dimensions). The network consists of a set of convolutional layers,
followed by a fully-connected layer. The last layer contains two outputs with soft-
max activation corresponding to the two classes. All layers use the max-feature-map
activation function [166], which acts as a feature selector and reduces the number of
feature maps by half on each layer. The network is then trained to discriminate be-
tween the natural and spoofed speech classes. Once the network is trained, it is used
to extract a high-level feature vector which is the output of the fully connected layer.
All the test utterances are processed to obtain high-level representations, which are
later classiﬁed with an external classiﬁer.
Other hand-crafted features. Many other features have also been used for re-
played speech detection in the context of the ASVspoof 2017 database. Even if
the performances of single systems using such features are not always high, they
are shown to be complementary when fused at the score level [167], similar to
conventional ASV research outside of the spooﬁng detection. These features in-
clude MFCC, IMFCC, rectangular ﬁlter cepstral coefﬁcients (RFCCs), PLP, CQCC,
spectral centroid magnitude coefﬁcients (SCMC), subband spectral ﬂux coefﬁcient
(SSFC), and variable length Teager energy operator energy separation algorithm-
instantaneous frequency cosine coefﬁcients (VESA-IFCC). Though, of course, one
usually then has to further train the fusion system, which makes the system more
involved concerning practical applications.
5 Advances in back-end classiﬁers
In the natural vs. spoof classiﬁcation problem, two main families of approaches
have been adopted, namely generative and discriminative. Generative approaches
include those of GMM-based classiﬁers and i-vector representations combined with
support vector machines (SVMs). As for discriminative approaches, deep learning
based techniques have become more popular. Finally, new deep learning end-to-
end solutions are emerging. Such techniques perform the typical pipeline entirely
through deep learning, from feature representation learning and extraction to the
ﬁnal classiﬁcation. While including such approaches into the traditional classiﬁers
category may not be the most precise, they are included in this classiﬁers section for
simplicity.
Authors Suppressed Due to Excessive Length
5.1 Generative approaches
Gaussian mixture model (GMM) classiﬁers. Considering two classes, namely nat-
ural and spoofed speech, one GMM can be learned for each class using appropriate
training data. In the classiﬁcation stage, an input utterance is processed to obtain
its likelihoods with respect to the natural and spoofed models. The resulting clas-
siﬁcation score is the log-likelihood ratio between the two competing hypotheses;
in effect, those of the input utterance belonging to the natural and to the spoofed
classes. A high score supports the former hypothesis, while a low score supports the
latter. Finally, given a test utterance, classiﬁcation can be performed by thresholding
the obtained score. If the score is above the threshold, the test utterance is classi-
ﬁed as natural, and otherwise, it is classiﬁed as spoof. Many proposed anti-spooﬁng
systems use GMM classiﬁers [146, 129, 136, 168, 155, 158, 148].
I-vector. The state-of-the-art paradigm for speaker veriﬁcation [169] has been
explored for spooﬁng detection [170, 171]. Typically, an i-vector is extracted from
an entire speech utterance and used as a low-dimensional, high-level feature which
is later classiﬁed by means of a binary classiﬁer, commonly cosine distance mea-
sure or support vector machine (SVM). Different amplitude- and phase-based fron-
tends [130, 138] can be employed for the estimation of i-vectors. A recent work
shows that data selection for i-vector extractor training (also known as T matrix) is
an important factor for achieving completive recognition accuracy [172].
5.2 Discriminative approaches
DNN classiﬁers. Deep learning based classiﬁers have been explored for use in the
task of natural and spoofed speech discrimination. In [173, 155], several front-ends
are evaluated with neural network classiﬁer consisting of several hidden layers with
sigmoid nodes and softmax output, which is used to calculate utterance posteriors.
However, the implementation detail of the DNNs - such the number of nodes, the
cost function, the optimization algorithm and the activation functions - is not pre-
cisely mentioned in those work and the lack of this very relevant information make
it difﬁcult to reproduce the results.
In a recent work [174], a ﬁve-layer DNN spooﬁng detection system is investi-
gated for ASVspoof 2015 which uses a novel scoring method, termed in the paper
as human log-likelihoods (HLLs). Each of the hidden layers has 2048 nodes with a
sigmoid activation function. The network has six softmax output layers. The DNN
is implemented using a computational network toolkit9 and trained with stochastic
gradient descent methods with dynamics information of acoustic features, such as
spectrum-based cepstral coefﬁcients (SBCC) and CQCC as input. The cross entropy
function is selected as the cost function and the maximum training epoch is chosen
as 120. The mini-batch size is set to 128. The proposed method shows considerable
9 https://github.com/Microsoft/CNTK
Introduction to Voice Presentation Attack Detection and Recent Advances
PAD detection performance. The author obtain an EER for S10 of 0.255% and aver-
age EER for all attacks of 0.045% when used with CQCC acoustic features. These
are the best reported performance in ASVspoof 2015 so far.
DNN-based end-to-end approaches. End-to-end systems aim to perform all the
stages of a typical spooﬁng detection pipeline, from feature extraction to classiﬁ-
cation, by learning the network parameters involved in the process as a whole. The
advantage of such approaches is that they do not explicitly require prior knowledge
of the spooﬁng attacks as required for the development of acoustic features. Instead,
the parameters are learned and optimised from the training data. In [175], a con-
volutional long short-term memory (LSTM) deep neural network (CLDNN) [176]
is used as an end-to-end solution for spooﬁng detection. This model receives input
in the form of a sequence of raw speech frames and outputs a likelihood for the
whole sequence. The CLDNN performs time-frequency convolution through CNN
to reduce spectral variance, long-term temporal modelling by using a LSTM, and
classiﬁcation using a DNN. Therefore, it is a entirely an end-to-end solution which
does not rely on any external feature representation. The works in [177, 138] pro-
pose other end-to-end solutions by combining convolutional and recurrent layers,
where the ﬁrst act as a feature extractor and the second models the long-term de-
pendencies and acts as a classiﬁer. Unlike the work in [175], the input data is the
FFT spectrogram of the speech utterance and not the raw speech signal. In [178],
the authors have investigated CNN-based end-to-end system for PAD where the raw
speech is used to jointly learn the feature extractor and classiﬁer. Score-level combi-
nation of this CNN system with standard long-term spectral statistics based system
shows considerable overall improvement.
6 Other PAD approaches
While most of the studies in voice PAD detection research focus on algorithmic
improvements for discriminating natural and artiﬁcial speech signals, some recent
studies have explored utilising additional information collected using special addi-
tional hardware to protect ASV system from presentation attacks [179, 180, 181,
182]. Since an intruder can easily collect voice samples for the target speakers using
covert recording; the idea there is to detect and recognise supplementary information
related to the speech production process. Moreover, by its nature, that supplemen-
tary information is difﬁcult, if not impossible, to mimic using spooﬁng methods in
the practical scenario. These PAD techniques have shown excellent recognition ac-
curacy in the spoofed condition, at the cost of additional setup in the data acquisition
step.
The work presented in [180, 181] utilises the phenomenon of , which is a dis-
tortion in human breath when it reaches a microphone [183]. During natural speech
production, the interactions between the airﬂow and the vocal cavities may result in
a sort of plosive burst, commonly know as pop noise, which can be captured via a
microphone. In the context of professional audio and music production, pop noise
Authors Suppressed Due to Excessive Length
is unwanted and is eliminated during the recording or mastering process. In the con-
text of ASV, however, it can help in the process of PAD. The basic principle is that
a replay sound from a loudspeaker does not involve the turbulent airﬂow generating
the pop noise as in the natural speech. The authors in [180, 181] have developed
a pop noise detector which eventually distinguishes natural speech from playback
recording as well as synthetic speech generated using VC and SS methods. In ex-
periments with 17 female speakers, a tandem detection system that combines both
single- and double-channel pop noise detection gives the lowest ASV error rates in
the PA condition.
The authors in [179] have introduced the use of a smartphone-based magnetome-
ter to detect voice presentation attack. The conventional loudspeakers, which are
used for playback during access of the ASV systems, generate sound using acoustic
transducer and generate a magnetic ﬁeld. The idea, therefore, is to capture the use
of loudspeaker by sensing the magnetic ﬁeld which would be absent from human
vocals. Experiments were conducted using playback from 25 different conventional
loudspeakers, ranging from low-end to high-end and placed in different distances
from the smartphone that contains the ASV system. A speech corpus of ﬁve speak-
ers was collected for the ASV experiments executed using an open-source ASV
toolkit, SPEAR10. Experiments were conducted with other datasets, using a simi-
larly limited number of speakers. The authors demonstrated that the magnetic ﬁeld
based detection can be reliable for the detection of playback within 6-8 cm from
the smartphone. They further developed a mechanism to detect the size of the sound
source to prevent the use of small speakers, such as ear phones.
The authors in [184, 185] utilise certain acoustics concepts to prevent ASV sys-
tems from PAs. They ﬁrst introduced a method [184] that estimates dynamic sound
source position (articulation position within mouth) of some speech sounds using
a small array using microelectromechanical systems (MEMS) microphones embed-
ded in mobile devices and compare it with loudspeakers, which have a ﬂat sound
source. In particular, the idea is to capture the dynamics of time-difference-of-arrival
(TDOA) in a sequence of speech sounds to the microphones of the smartphone.
Such unique TDOA changes, which do not exist under replay conditions, are used
for detecting replay attacks. The similarities between the TDOAs of test speech and
user templates are measured using probability function under Gaussian assumption
and correlation measure as well as their combinations. Experiments involving 12
speakers and three different types of smartphone demonstrate a low EER and high
PAD accuracy. The proposed method is seen to remain robust despite the change of
smartphones during the test and the displacements.
In [185], the same research group has used the idea of the Doppler effect to
detect the replay attack. The idea here is to capture the articulatory gestures of the
speakers when they speak a pass-phrase. The smartphone acts as a Doppler radar and
transmits a high frequency tone at 20 kHz from the built-in speaker and senses the
reﬂections using the microphone during authentication process. The movement of
the speaker’s articulators during vocalisation creates a speaker-dependent Doppler
10 https://www.idiap.ch/software/bob/docs/bob/bob.bio.spear/stable/index.html
Introduction to Voice Presentation Attack Detection and Recent Advances
frequency shift at around 20 kHz, which is stored along with the speech signal dur-
ing the speaker-enrolment process. During a playback attack, the Doppler frequency
shift will be different due to the lack of articulatory movements. Energy-based fre-
quency features and frequency-based energy features are computed from a band of
19.8 kHz and 20.2 kHz. These features are used to discriminate between the natu-
ral and replayed voice; and the similarity scores are measured in terms of Pearson
correlation coefﬁcient. Experiments are conducted with a dataset of 21 speakers and
using three different smartphones. The data also includes test speech for replay at-
tack with different loudspeakers and for impersonation attack with four different
impersonators. The proposed system was demonstrated to be effective in achieving
low EER for both types of attacks. Similar to [184], the proposed method indicated
robustness to the phone placement.
Fig. 5: Throat-microphones used in [182] [Reprinted with permission from
IEEEACM Transactions on (T-ASL) Audio, Speech, and Language Processing].
The work in [182] introduces the use of a speciﬁc non-acoustic sensor, throat mi-
crophone (TM), or laryngophone, to enhance the performance of the voice PAD
system. An example of such microphones is shown in Fig. 5. The TM is used
with a conventional acoustic microphone (AM) in a dual-channel framework for
robust speaker recognition and PAD. Since this type of microphone is attached to
the speaker’s neck, it would be difﬁcult for the attacker to obtain a covert recording
of the target speaker’s voice. Therefore, one possibility for the intruder is to use the
stolen recording from an AM and to try to record it back using a TM for access-
ing the ASV system. A speech corpus of 38 speakers was collected for the ASV
experiments. The dual-channel setup yielded considerable ASV for both licit and
spoofed conditions. The performance is further improved when this ASV system is
integrated with the dual-channel based PAD. The authors show zero FAR for replay
imposters by decision fusion of ASV and PAD.
Authors Suppressed Due to Excessive Length
All of the above new PAD methods deviating from the “mainstream” of PAD re-
search in ASV are reported to be reliable and useful in speciﬁc application scenarios
for identifying presentation attacks. The methods are also fundamentally different
and difﬁcult to compare in the same settings. Since the authors focus on the method-
ological aspects, experiments are mostly conducted on a dataset of limited number
of speakers. Extensive experiments with more subjects from diverse environmental
conditions should be performed to assess their suitability for real-world deployment.
7 Future directions of anti-spooﬁng research
The research in ASV anti-spooﬁng is becoming popular and well-recognised in the
speech processing and voice-biometric community. The state-of-the-art spooﬁng de-
tector gives promising accuracy in the benchmarking of spooﬁng countermeasures.
Further work is needed to address a number of speciﬁc issues regarding its prac-
tical use. A number of potential topics for consideration in further work are now
discussed.
• Noise, reverberation and channel effect. Recent studies indicate that spoof-
ing countermeasures offer little resistance to additive noise [186, 187], rever-
beration [188] and channel effect [189] even though their performances on
“clean” speech corpus are highly promising. The relative degradation of per-
formance is actually much worse than the degradation of a typical ASV system
under the similar mismatch condition. One reason could be that, at least until
the ASVspoof 2017 evaluation, the methodology developed has been driven in
clean, high-quality speech. In other words, the community might have devel-
oped its methods implicitly for laboratory testing. The commonly used speech
enhancement algorithms also fail to reduce the mismatch due to environmental
differences, though multi-condition training [187] and more advanced training
methods [190] have been found useful. The study presented in [189] shows con-
siderable degradation of PAD performance even in matched acoustic conditions.
The feature settings used for the original corpus gives lower accuracy when both
training and test data are digitally processed with the telephone channel effect.
These are probably because the spooﬁng artefacts themselves act as extrinsic
variabilities which degrade the speech quality in some way. Since the task of
spooﬁng detection is related to detecting those artefacts, the problem becomes
more difﬁcult in the presence of small external effects due to variation in envi-
ronment and channel. These suggests further investigations need to be carried
out for the development of robust spooﬁng countermeasures.
• Generalisation of spooﬁng countermeasures. The property of spooﬁng coun-
termeasures for detecting new kinds of speech presentation attack is an impor-
tant requirement for their application in the wild. Study explores that coun-
termeasure methods trained with a class of spooﬁng attacks fail to generalise
this for other classes of spooﬁng attack [191, 167]. For example, PAD systems
trained with VC and SS based spoofed speech give a very poor performance for
Introduction to Voice Presentation Attack Detection and Recent Advances
playback detection [192]. The results of the ﬁrst two ASVspoof challenges also
reveal that detecting the converted speech created with an “unknown” method
or the playback voice recording in a new replay session are difﬁcult to detect.
These clearly indicate the overﬁtting of PAD systems with available training
data. Therefore, further investigation should be conducted to develop attack-
independent universal spooﬁng detector. Other than the unknown attack issue,
generalisation is also an important concern for cross-corpora evaluation of the
PAD system [193]. This speciﬁc topic is discussed in chapter 19 of this book.
• Investigations with new spooﬁng methods. The studies of converted spoof
speech mostly focused on methods based on classical signal processing and
machine learning techniques. Recent advancements in VC and SS research
with deep learning technology show signiﬁcant improvements in creating high
quality synthetic speech [52]. The GAN [194] can be used to create (genera-
tor) spoofed voices with relevant feedback from the spooﬁng countermeasures
(discriminator). Some preliminary studies demonstrate that the GAN-based ap-
proach can make speaker veriﬁcation systems more vulnerable to presentation
attacks [195, 66]. More detailed investigations should be conducted on this di-
rection for the development of countermeasure technology to guard against this
type of advanced attack.
• Joint operations of PAD and ASV. The ultimate goal of developing PAD sys-
tem is to protect the recogniser, the ASV system from imposters with spoofed
speech. So far, the majority of the studies focused on the evaluation of stan-
dalone countermeasures. The integration of these two systems is not trivial num-
ber of reasons. First, standard linear output score fusion techniques, being ex-
tensively used to combine homogenous ASV system, are not appropriate since
the ASV and its countermeasures are trained to solve two different tasks. Sec-
ond, an imperfect PAD can increase the false alarm rate by rejecting genuine ac-
cess trials [196]. Thirdly, and more fundamentally, it is not obvious whether im-
provements in standalone spooﬁng countermeasures should improve the overall
system as a whole: a nearly perfect PAD system with close to zero EER may
fail to protect ASV system in practice if not properly calibrated [197]. In a re-
cent work [198], the authors propose a modiﬁcation in a GMM-UBM based
ASV system to make it suitable for both licit and spoofed conditions. The joint
evaluation of PAD and ASV, as well as their combination techniques, certainly
deserves further attention. Among other feedback received from the attendees
of the ASVspoof 2017 special session organised during INTERSPEECH 2017,
it was proposed that the authors of this chapter consider shifting the focus from
standalone spooﬁng to more ASV-centric solutions in future. We tend to agree.
In our recent work [199], we propose a new cost function for joint assessment of
PAD and ASV system. In another work [200], we propose a new fusion method
for combining scores of countermeasures and recognisers. This work also ex-
plores speech features which can be used both for PAD and ASV.
Authors Suppressed Due to Excessive Length
8 Conclusion
This contribution provides an introduction to the different voice presentation attacks
and their detection methods. It then reviews previous works with a focus on recent
progress in assessing the performance of PAD systems. We have also brieﬂy re-
viewed two recent ASVspoof challenges organised for the detection of voice PAs.
This study includes discussion of recently developed features and the classiﬁers
which are predominantly used in ASVspoof evaluations. We further include an
extensive survey on alternative PAD methods. Apart from the conventional voice-
based systems that use statistical properties of natural and spoofed speech for their
discrimination, these recently developed methods utilise a separate hardware for the
acquisition of other signals such as pop noise, throat signal, and extrasensory signals
with smartphones for PAD. The current status of these non-mainstream approaches
to PAD detection is somewhat similar to the status of the now more-or-less standard
methods for artiﬁcial speech and replay PAD detection some three to four years ago:
they are innovative and show promising results, but the pilot experiments have been
carried out on relatively small and/or proprietary datasets, leaving an open question
as to how scalable or generalisable these solutions are in practice. Nonetheless, in
the long run and noting especially the rapid development of speech synthesis tech-
nology, it is likely that the quality of artiﬁcial/synthetic speech will eventually be
indistinguishable from that of natural human speech. Such future spooﬁng attacks
therefore could not be detected using the current mainstream techniques that focus
on spectral or temporal details of the speech signal, but will require novel ideas that
beneﬁt from auxiliary information, rather than just the acoustic waveform.
In the past three years, the progress in voice PAD research has been accelerated
by the development and free availability of speech corpus such as the ASVspoof
series, SAS, BTAS 2016, AVSpoof. The work discussed several open challenges
which show that this problem requires further attention to improving robustness due
to mismatch condition, generalisation to new type of presentation attacks, and so
on. Results from joint evaluations with integrated ASV system are also an important
requirement for practical applications of PAD research. We think, however, that this
extensive review will be of interest not only to those involved in voice PAD research
but also to voice-biometrics researchers in general.
Appendix A. Action towards reproducible research
A.1. Speech corpora
1. Spooﬁng and Anti-Spooﬁng (SAS) database v1.0: This database presents the
ﬁrst version of a speaker veriﬁcation spooﬁng and anti-spooﬁng database,
named SAS corpus [201]. The corpus includes nine spooﬁng techniques, two
of which are speech synthesis, and seven are voice conversion.
Introduction to Voice Presentation Attack Detection and Recent Advances
Download link: http://dx.doi.org/10.7488/ds/252
2. ASVspoof 2015 database: This database has been used in the ﬁrst Automatic
Speaker Veriﬁcation Spooﬁng and Countermeasures Challenge (ASVspoof 2015).
Genuine speech is collected from 106 speakers (45 male, 61 female) and with
no signiﬁcant channel or background noise effects. Spoofed speech is gener-
ated from the genuine data using a number of different spooﬁng algorithms.
The full dataset is partitioned into three subsets, the ﬁrst for training, the second
for development and the third for evaluation.
Download link: http://dx.doi.org/10.7488/ds/298
3. ASVspoof 2017 database: This database has been used in the Second Automatic
Speaker Veriﬁcation Spooﬁng and Countermeasuers Challenge: ASVspoof 2017.
This database makes an extensive use of the recent text-dependent RedDots cor-
pus, as well as a replayed version of the same data. It contains a large amount of
speech data from 42 speakers collected from 179 replay sessions in 62 unique
replay conﬁgurations.
Download link: http://dx.doi.org/10.7488/ds/2313
A.2. Software packages
1. Feature extraction techniques for anti-spooﬁng: This package contains the
MATLAB implementation of different acoustic feature extraction schemes as
evaluated in [146].
Download link: http://cs.joensuu.fi/˜sahid/codes/AntiSpoofing_Features.zip
2. Baseline spooﬁng detection package for ASVspoof 2017 corpus: This package
contain the MATLAB implementations of two spooﬁng detectors employed as
baseline in the ofﬁcial ASVspoof 2017 evaluation. They are based on constant
Q cepstral coefﬁcients (CQCC) [137] and Gaussian mixture model classiﬁers.
Download link: http://audio.eurecom.fr/software/ASVspoof2017_baseline_countermeasu